{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67e9bff-db75-43e1-8cca-1163f1724769",
   "metadata": {},
   "source": [
    "# Text Generation with Python and Keras\n",
    "\n",
    "+ Part One\n",
    "\n",
    "1. Read Moby Dick .txt files into pandas\n",
    "2. Process Text\n",
    "3. Clean Text\n",
    "4. Tokenize the Text and create Sequences with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bab26109-ce33-4358-98bc-6feef020005d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to read in a .txt file\n",
    "# Once definition is written, a .txt file with four chapter of moby dick will appear below\n",
    "\n",
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "        \n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e7fa31-9bc4-4399-a371-ab89d79505c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "# read_file('moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c54c445e-7ca6-4804-bb4b-551e87158709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing spacy library to tokenize text\n",
    "# we will also disable any parts of th\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('en_core_web_md', disable = ['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb31692-088b-4a0b-9d6d-6efcaf040530",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dbb838b-ea6c-442a-9899-092ca684798e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4f31c33-0175-4593-a9cd-d73f813dd340",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file('moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10349201-9db8-45c5-9171-88d0904ad1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = separate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9100319-7550-4d22-b011-5adb0129bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7c9d6f38-c9cf-41fd-8628-95cc3fcc0c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11338"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ad29959-288c-45eb-809d-6369f6732b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25 words --> Neural Network to predict the next word # 26"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae13e2-48ca-4cd3-b7bb-dadd702d7fe0",
   "metadata": {},
   "source": [
    "## Create Sequence of Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8bdc5e9-0512-4c4a-adea-252bd43237cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# organize into sequences of tokens\n",
    "train_len = 25+1 #training words, then one target word\n",
    "\n",
    "# Creating an empty list of sequences\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)): # range is the training length, up to the length of all of the tokens \n",
    "    \n",
    "    # grab the amount of characters in train_len\n",
    "    seq = tokens[i-train_len:i] # i minus train_len up to i \n",
    "    \n",
    "    # Add to text_sequences using append\n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bc124af5-6bf8-4cab-8463-3bfb5cb479a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51e2b86e-4567-4446-8607-d15ced5250a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[1]) # moves one word over to the right - as we can see it started with call me and now it starts with me"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a500075-785a-4c3c-bfd5-415e10832a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[2]) # on this sequence again it moved one word over to the right, starting with ishmael"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1abe8837-4793-468a-9add-cd7700d3715c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11312"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b274272b-0ae2-4e1d-9a10-ad829d21995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c31de1d-7477-4045-9088-2b948ef3a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "# the number is an id for the word - as it is unique to each word\n",
    "\n",
    "tokenizer = Tokenizer() # create the tokenizer object\n",
    "tokenizer.fit_on_texts(text_sequences) # calling on tokenizers fit_on_texts and provide the text_sequences\n",
    "sequences = tokenizer.texts_to_sequences(text_sequences) # calling on texts_to_sequences and replaces texts sequences to sequences of numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d9aa7a9-34ca-4543-a45d-0b837468c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dc46620-ea92-4f9b-8ce2-f47bf6299c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c7703fe-87ed-42ba-8c05-cc402b192ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956 : call\n",
      "14 : me\n",
      "263 : ishmael\n",
      "51 : some\n",
      "261 : years\n",
      "408 : ago\n",
      "87 : never\n",
      "219 : mind\n",
      "129 : how\n",
      "111 : long\n",
      "954 : precisely\n",
      "260 : having\n",
      "50 : little\n",
      "43 : or\n",
      "38 : no\n",
      "314 : money\n",
      "7 : in\n",
      "23 : my\n",
      "546 : purse\n",
      "3 : and\n",
      "150 : nothing\n",
      "259 : particular\n",
      "6 : to\n",
      "2713 : interest\n",
      "14 : me\n",
      "24 : on\n"
     ]
    }
   ],
   "source": [
    "# for i in sequences, print out the id : followed by word\n",
    "for i in sequences[0]:\n",
    "    print(f'{i} : {tokenizer.index_word[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28d49de8-4b4a-4d13-b632-8437cd8cf3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.word_counts # counts how many times each words shows up ie. Ishmael shows up 133 times in this .txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d42704d7-f896-4cb9-b63f-a1ea61eeb850",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "437e61cf-3d85-415e-af91-ee50e8f314f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dcb72652-8c10-4bab-8d5c-108eda68c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences) # transforming sequences the list into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc489934-6522-491d-99b3-4afe236355ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 956,   14,  263, ..., 2713,   14,   24],\n",
       "       [  14,  263,   51, ...,   14,   24,  957],\n",
       "       [ 263,   51,  261, ...,   24,  957,    5],\n",
       "       ...,\n",
       "       [ 952,   12,  166, ...,  262,   53,    2],\n",
       "       [  12,  166, 2712, ...,   53,    2, 2718],\n",
       "       [ 166, 2712,    3, ...,    2, 2718,   26]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# last word on the right - ie. 24 in the first row is the target word or in other words the label\n",
    "# the features would be the 25 numbers starting from 956 and ending at 14\n",
    "\n",
    "sequences # formatted sequences into the numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709f632c-d55a-48b3-b139-92a6a977a412",
   "metadata": {},
   "source": [
    "## Creating an LSTM based model\n",
    "\n",
    "# Approach\n",
    "\n",
    "+ Create the LSTM based model\n",
    "+ Split the data into features and labels\n",
    "\n",
    "  - X Features (First 25 words of Sequence)\n",
    "  - Y Label (Next word after the sequence)\n",
    "\n",
    "\n",
    "+ Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00ef358b-257f-4e67-8548-553fb71ea887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76ef458b-bda1-4eb7-9acf-ec563b87992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, 25, input_length = seq_len))\n",
    "    model.add(LSTM(150, return_sequences = True))\n",
    "    model.add(LSTM(150))\n",
    "    model.add(Dense(150, activation = 'relu')) # relu = rectified linear activation function. Output directly if it is positive or else it will output zero.\n",
    "    \n",
    "    model.add(Dense(vocabulary_size, activation = 'softmax'))\n",
    "    \n",
    "    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34f5e5f-91fa-4585-953f-4ccb93008e0c",
   "metadata": {},
   "source": [
    "# Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d40530-f193-4547-84a4-5bd465f9023b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed86ba-6a7e-405a-9411-77de942b5233",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7e1746-f50a-4c6b-a467-d2bb5b294bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa673ff-fd10-4660-b782-e7ad95d37aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f54243-4c02-41c1-9fff-ae0deb924f3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6cd645-a642-4223-b83a-fed59aa185d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a503657-f0ef-4046-94fa-1136d890957a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3444c5-c69b-4a0a-b67d-a1fcc1646d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66b8d71-d6f8-48c8-80d1-80c8b611aa10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a130a96-af78-4a80-b06c-f02e41ee1376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389816c2-279e-4a2e-852c-b73a1e47c0f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514852ac-2e39-43fd-8578-7c0110d495f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf25f9-b868-4b0d-8374-fb2d5782bce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e3363b-7a30-4176-b218-5b93d3ce990e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a56b6-c5ad-4613-9390-2a1420c36452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2b6cd5-0487-4c20-8556-fdd2dcc77566",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f737ae-b15e-437e-aeba-0e76a7f6b711",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa68d538-dc90-4d2b-83dd-725c235bad4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a926e66-14b9-4e22-a408-0ef7c28340a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c179c740-ab54-4d00-a20b-9fb65ece61fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9919e88d-bb73-464d-ac83-241e8fa56ec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fb266-27d9-4973-bfda-ab9fd7429c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
